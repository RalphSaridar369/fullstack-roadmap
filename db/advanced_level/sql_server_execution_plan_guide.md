 # SQL Server Execution Plan Optimization Guide

## Overview

A SQL Server execution plan is the database engine's strategy for executing a query. Understanding execution plans, particularly the performance characteristics of different scan types and join algorithms, is critical for query optimization. This guide focuses on practical optimization using SQL Server execution plan analysis.

## What is an Execution Plan?

An execution plan shows the sequence of operations SQL Server uses to execute a query. The query optimizer evaluates multiple execution strategies and selects the one with the lowest estimated cost based on:

- Available indexes
- Table and index statistics
- Data distribution and cardinality
- Join methods and order
- Available memory and parallelism
- Filter selectivity

---

## Scan Types: Ranked by Performance (Worst to Best)

Understanding scan types is crucial for optimization. Here's a ranking from worst to best performance:

### 7. Table Scan (WORST)

**What it is:** Reads every single row in the entire table, page by page.

**Performance Impact:**
- Extremely slow on large tables
- High I/O cost
- Blocks other operations
- No index utilization

**When it occurs:**
- No suitable index exists
- No WHERE clause (SELECT * FROM table)
- Query optimizer determines it's cheaper than index operations (very small tables)
- Statistics are outdated

**Example:**
```sql
SELECT * FROM Orders WHERE CustomerNote LIKE '%urgent%'
-- If no index on CustomerNote, full table scan required
```

**Cost Indicators:**
- Cost: Very High (often 50-90% of query cost)
- Estimated Rows: Total table row count
- Actual Rows: Total table row count

**Optimization:**
- Create appropriate indexes
- Add WHERE clauses to filter data
- Update statistics

---

### 6. Clustered Index Scan

**What it is:** Reads all rows in order using the clustered index (table structure).

**Performance Impact:**
- Better than table scan (data is ordered)
- Still reads entire table
- High I/O on large tables
- Moderate CPU usage

**When it occurs:**
- Query needs most/all rows from table
- No suitable non-clustered index
- WHERE clause not selective enough
- Covering index doesn't exist

**Example:**
```sql
SELECT * FROM Orders WHERE OrderDate >= '2020-01-01'
-- If query returns 80%+ of rows, optimizer may choose clustered scan
```

**Cost Indicators:**
- Cost: High (often 30-70% of query cost)
- Estimated Rows: Large percentage of table
- Logical Reads: High

**Optimization:**
- Create filtered or covering indexes
- Make WHERE clauses more selective
- Consider partitioning for large tables

---

### 5. Index Scan (Non-Clustered)

**What it is:** Reads all rows from a non-clustered index.

**Performance Impact:**
- Better than clustered scan (smaller data structure)
- Still reads entire index
- May require key lookups for additional columns
- Moderate I/O cost

**When it occurs:**
- Index exists but isn't selective for the query
- Searching for range that covers large portion of index
- Index is used for sorting but requires full scan

**Example:**
```sql
SELECT OrderID, CustomerID, OrderDate, TotalAmount 
FROM Orders 
WHERE OrderDate >= '2020-01-01'
-- Index on OrderDate exists but returns too many rows
```

**Cost Indicators:**
- Cost: Moderate-High (20-50% of query cost)
- Estimated Rows: Large subset of table
- Logical Reads: Moderate

**Optimization:**
- Create covering indexes
- Add more selective predicates
- Consider filtered indexes
- Update statistics

---

### 4. Index Seek with Lookups (Key Lookup / RID Lookup)

**What it is:** Uses index to find rows, then looks up additional columns from base table/clustered index.

**Performance Impact:**
- Good for finding rows
- Extra overhead for each lookup
- Performance degrades with many lookups
- Random I/O pattern

**When it occurs:**
- Non-clustered index doesn't include all needed columns
- Selective WHERE clause but non-covering index
- Typically with bookmark lookups

**Example:**
```sql
SELECT OrderID, CustomerID, TotalAmount, ShippingAddress
FROM Orders 
WHERE CustomerID = 12345
-- Index on CustomerID exists but doesn't include ShippingAddress
```

**Cost Indicators:**
- Index Seek Cost: Low (5-15%)
- Key Lookup Cost: Can be high (30-60%) if many rows
- Total Cost: Moderate

**Optimization:**
- Create covering indexes with INCLUDE clause
- Reduce columns in SELECT list
- Consider indexed views

**Tipping Point:** If Key Lookups > 20-30% of rows, optimizer may switch to Index Scan or Clustered Index Scan instead.

---

### 3. Index Seek (Non-Covering)

**What it is:** Efficiently locates specific rows using a non-clustered index B-tree structure.

**Performance Impact:**
- Fast row location
- Minimal I/O
- Logarithmic search time O(log n)
- May need additional lookups for missing columns

**When it occurs:**
- Equality or range predicates on indexed columns
- Selective WHERE clauses
- Index exists and statistics are current

**Example:**
```sql
SELECT OrderID, CustomerID, OrderDate
FROM Orders 
WHERE CustomerID = 12345
-- Non-clustered index on CustomerID
```

**Cost Indicators:**
- Cost: Low (5-20% of query cost)
- Estimated Rows: Small subset
- Logical Reads: Low
- Seek Predicates: Present

**Optimization:**
- Already efficient
- Consider making it covering to eliminate lookups

---

### 2. Clustered Index Seek

**What it is:** Directly navigates to specific rows using the clustered index (primary key).

**Performance Impact:**
- Very fast
- Direct access to data rows
- No additional lookups needed
- Minimal I/O

**When it occurs:**
- Predicate on clustered index key (usually primary key)
- Point lookups or small range queries
- Supporting nested loop joins

**Example:**
```sql
SELECT * FROM Orders WHERE OrderID = 12345
-- OrderID is clustered index (primary key)
```

**Cost Indicators:**
- Cost: Very Low (1-10% of query cost)
- Estimated Rows: Very small (often 1)
- Logical Reads: Very low (1-5 pages)

**Optimization:**
- Already highly efficient
- Ensure statistics are current

---

### 1. Index Seek with Covering Index (BEST)

**What it is:** Index contains all columns needed by the query, no lookups required.

**Performance Impact:**
- Fastest possible access method
- Minimal I/O (only index pages)
- No additional table/clustered index access
- Optimal for most queries

**When it occurs:**
- Non-clustered index includes all SELECT, WHERE, JOIN, and ORDER BY columns
- Properly designed covering index
- Selective predicates

**Example:**
```sql
-- Covering index: CREATE NONCLUSTERED INDEX IX_Orders_Covering 
-- ON Orders(CustomerID) INCLUDE (OrderDate, TotalAmount)

SELECT OrderDate, TotalAmount
FROM Orders 
WHERE CustomerID = 12345
```

**Cost Indicators:**
- Cost: Minimal (1-5% of query cost)
- Estimated Rows: Small
- Logical Reads: Minimal
- No Key Lookups present
- "Index Seek (NonClustered)" with all columns available

**Optimization:**
- Already optimal
- Monitor index size and maintenance cost
- Ensure index is actually being used

---

## Performance Summary: Scans

| Rank | Scan Type | Typical Cost | I/O | Use Case | Optimization Priority |
|------|-----------|--------------|-----|----------|----------------------|
| 1 | Covering Index Seek | 1-5% | Minimal | Best case | âœ“ Maintain |
| 2 | Clustered Index Seek | 1-10% | Very Low | Point lookups | âœ“ Maintain |
| 3 | Index Seek | 5-20% | Low | Selective queries | Consider covering |
| 4 | Index Seek + Lookups | 20-50% | Moderate | Partial coverage | âš ï¸ Create covering index |
| 5 | Index Scan | 20-50% | Moderate-High | Large result sets | âš ï¸ Add selectivity |
| 6 | Clustered Index Scan | 30-70% | High | Full table reads | âš ï¸ Add indexes/filters |
| 7 | Table Scan | 50-90% | Very High | No indexes | ðŸš¨ Critical - Add indexes |

---

## Join Algorithms: Ranked by Performance (Worst to Best)

Join performance depends heavily on data volume, indexes, and memory. Here's a general ranking:

### 5. Nested Loops with Table/Index Scans (WORST)

**What it is:** Outer loop iterates through one table, inner loop scans entire second table for each row.

**Performance Impact:**
- Extremely slow: O(n * m) where n and m are row counts
- Exponential cost growth
- No index utilization on inner table
- High CPU and I/O

**When it occurs:**
- No suitable indexes on join columns
- Very poor join conditions
- Outdated statistics
- Usually indicates a serious problem

**Example:**
```sql
SELECT o.OrderID, c.CustomerName
FROM Orders o
JOIN Customers c ON SUBSTRING(o.CustomerCode, 1, 5) = c.CustomerID
-- Function on join column prevents index usage
```

**Cost Indicators:**
- Cost: Extreme (often 80-95% of query cost)
- Estimated Rows: Outer * Inner rows
- Number of Executions: Very high on inner table
- Warnings: May show missing index

**Optimization:**
- Create indexes on join columns
- Remove functions from join predicates
- Rewrite query logic
- Update statistics

**Example Cost:**
- Outer: 10,000 rows
- Inner: 50,000 rows (full scan each time)
- Operations: 10,000 Ã— 50,000 = 500,000,000 comparisons

---

### 4. Hash Match (Spilling to TempDB)

**What it is:** Hash join that runs out of memory and spills hash table to disk.

**Performance Impact:**
- Severe performance degradation
- Heavy tempdb I/O
- Memory pressure indicators
- Much slower than in-memory hash join

**When it occurs:**
- Insufficient memory grant
- Very large tables being joined
- Multiple concurrent queries
- Underestimated row counts

**Example:**
```sql
SELECT o.OrderID, od.ProductID, od.Quantity
FROM Orders o
JOIN OrderDetails od ON o.OrderID = od.OrderID
WHERE o.OrderDate >= '2020-01-01'
-- Returns millions of rows, insufficient memory
```

**Cost Indicators:**
- Hash Match Warnings: "Operator used tempdb"
- Spills Count: > 0
- Memory Grant: Insufficient
- I/O Cost: Very High
- Estimated vs Actual Rows: Large discrepancy

**Optimization:**
- Update statistics (fix cardinality estimates)
- Add memory to server
- Add indexes to reduce row counts earlier
- Break query into smaller chunks
- Use query hint: OPTION (HASH GROUP)

---

### 3. Nested Loops (Non-Optimal)

**What it is:** Outer loop iterates rows, inner loop performs index seek for each row, but data volumes aren't ideal.

**Performance Impact:**
- Acceptable for small datasets
- Poor for medium-large datasets
- Many seeks become expensive
- CPU intensive

**When it occurs:**
- Joining small outer table to large inner table
- Index exists but row count moderate-high
- Statistics underestimate result set
- Better algorithms could be used

**Example:**
```sql
SELECT o.OrderID, c.CustomerName
FROM Orders o
JOIN Customers c ON o.CustomerID = c.CustomerID
WHERE o.OrderDate = '2024-01-15'
-- Returns 1,000 orders (performs 1,000 seeks into Customers)
```

**Cost Indicators:**
- Cost: Moderate-High (30-60%)
- Number of Executions: High on inner table
- Estimated Rows: Moderate
- Logical Reads: Moderate-High

**Optimization:**
- Consider forcing Hash or Merge join
- Add covering indexes
- Reduce outer table row count
- Update statistics

**Rule of Thumb:** 
- Good: < 100 outer rows
- Acceptable: 100-1,000 outer rows
- Poor: 1,000-10,000 outer rows
- Very Poor: > 10,000 outer rows

---

### 2. Hash Match (In-Memory)

**What it is:** Builds hash table from smaller input, probes with larger input.

**Performance Impact:**
- Good for large datasets
- One pass through each table
- Memory intensive
- Unordered output

**When it occurs:**
- Joining large tables
- No suitable indexes for other join types
- Equality predicates
- Sufficient memory available

**Example:**
```sql
SELECT o.OrderID, od.ProductID, od.Quantity
FROM Orders o
JOIN OrderDetails od ON o.OrderID = od.OrderID
WHERE o.OrderDate >= '2024-01-01'
-- Both tables large, equi-join, sufficient memory
```

**Cost Indicators:**
- Cost: Moderate (20-40% of query cost)
- Memory Grant: Adequate
- No tempdb spills
- Estimated Rows: Large on both sides

**Best For:**
- Large to large table joins
- No indexes on join columns
- Equi-joins (equality predicates)
- Sufficient memory available

**Performance:**
- Time Complexity: O(n + m)
- One scan of build input (smaller table)
- One scan of probe input (larger table)

**Optimization:**
- Already efficient for large joins
- Ensure sufficient memory
- Update statistics for accurate memory grants
- Consider adding indexes if frequently run

---

### 1. Nested Loops (Optimal) - Index Seek Pattern (BEST for small datasets)

**What it is:** Outer table is small, each row performs efficient index seek on inner table.

**Performance Impact:**
- Fastest for small outer table
- Minimal I/O
- Leverages indexes perfectly
- Low CPU usage

**When it occurs:**
- Small outer table (< 100 rows)
- Excellent index on inner table
- Selective WHERE clause
- Point lookups or small ranges

**Example:**
```sql
SELECT o.OrderID, c.CustomerName, c.Email
FROM Orders o
JOIN Customers c ON o.CustomerID = c.CustomerID
WHERE o.OrderID = 12345
-- Returns 1 order, performs 1 seek into Customers
```

**Cost Indicators:**
- Cost: Very Low (5-15% of query cost)
- Number of Executions: Very low
- Logical Reads: Minimal
- Actual Rows: Small

**Sweet Spot:**
- Outer table: 1-100 rows
- Inner table: Any size with good index
- Join on indexed columns
- Highly selective predicates

**Performance:**
- 1 row outer: 1 seek = Best case
- 10 rows outer: 10 seeks = Excellent
- 100 rows outer: 100 seeks = Good
- 1,000 rows outer: 1,000 seeks = Consider other joins

---

### 1. Merge Join (BEST for large sorted datasets)

**What it is:** Simultaneously scans two sorted inputs, matching rows as it goes.

**Performance Impact:**
- Fastest for large pre-sorted datasets
- One pass through each table
- Minimal memory usage
- Sorted output

**When it occurs:**
- Both inputs already sorted on join columns
- Clustered indexes on join columns
- Data ordered by indexes
- Equality or range predicates

**Example:**
```sql
SELECT o.OrderID, od.ProductID, od.Quantity
FROM Orders o
JOIN OrderDetails od ON o.OrderID = od.OrderID
-- Both tables have clustered indexes on OrderID
```

**Cost Indicators:**
- Cost: Low (10-25% of query cost)
- Ordered: True on both inputs
- No sort operations needed
- Logical Reads: Low

**Best For:**
- Large to large table joins
- Both tables indexed/sorted on join key
- One-to-many relationships
- Range joins (BETWEEN)

**Performance:**
- Time Complexity: O(n + m)
- One scan of each input
- No memory overhead
- No tempdb usage

**Requirements:**
- Both inputs must be sorted on join key
- Equality join predicates
- Compatible sort orders
- Current statistics

**Optimization:**
- Create clustered or non-clustered indexes on join columns
- Ensure indexes are maintained
- Best performance with clustered indexes

---

## Performance Summary: Joins

| Rank | Join Type | Best For | Rows | Memory | I/O | Optimization |
|------|-----------|----------|------|--------|-----|--------------|
| 1 | Merge Join | Large sorted tables | Large | Low | Low | âœ“ Maintain indexes |
| 1 | Nested Loops (Optimal) | Small outer, indexed inner | Small | Low | Minimal | âœ“ Maintain indexes |
| 2 | Hash Match (Memory) | Large unsorted tables | Large | High | Moderate | Ensure memory |
| 3 | Nested Loops (Non-optimal) | Medium datasets | Medium | Low | Moderate | âš ï¸ Add indexes/reduce rows |
| 4 | Hash Match (Spill) | Large tables, low memory | Large | Very High | Very High | ðŸš¨ Fix statistics/memory |
| 5 | Nested Loops (No index) | Should never occur | Any | Low | Extreme | ðŸš¨ Critical - Add indexes |

---

## SQL Server Execution Plan: Key Fields for Optimization

When analyzing execution plans in SQL Server Management Studio (SSMS), focus on these critical fields:

### 1. Operator Cost (Relative)

**Location:** Shown as percentage on each operator

**What it tells you:**
- Which operations consume most resources
- Where to focus optimization efforts
- Bottleneck identification

**How to use:**
```
Look for operators with > 20% cost
These are your primary optimization targets
```

**Action:**
- Operators > 50%: Critical priority
- Operators 20-50%: High priority
- Operators 10-20%: Medium priority
- Operators < 10%: Low priority (unless frequent)

---

### 2. Estimated vs. Actual Number of Rows

**Location:** Hover over operator, compare "Estimated Number of Rows" to "Actual Number of Rows"

**What it tells you:**
- Statistics accuracy
- Cardinality estimation issues
- Whether optimizer made correct choices

**How to use:**
```
Ratio = Actual Rows / Estimated Rows

Ratio > 10x or < 0.1x indicates serious problem
```

**Example:**
```
Estimated: 100 rows
Actual: 50,000 rows
Ratio: 500x â† Major problem!
```

**Action:**
- Large discrepancy: Update statistics immediately
- Consistent discrepancy: Consider query rewrite
- Extreme variance: Check data distribution

**Fix:**
```sql
-- Update statistics
UPDATE STATISTICS TableName WITH FULLSCAN;

-- Check statistics
DBCC SHOW_STATISTICS('TableName', 'IndexName');

-- Auto-update statistics
ALTER DATABASE YourDB SET AUTO_UPDATE_STATISTICS ON;
```

---

### 3. Logical Reads

**Location:** SET STATISTICS IO ON; output

**What it tells you:**
- Number of 8KB pages read from cache/disk
- I/O cost of query
- Which tables are expensive to access

**How to use:**
```sql
SET STATISTICS IO ON;
GO

SELECT * FROM Orders WHERE CustomerID = 12345;
GO

-- Output example:
-- Table 'Orders'. Scan count 1, logical reads 2500, physical reads 0
```

**Interpretation:**
- Logical reads < 100: Excellent
- Logical reads 100-1,000: Good
- Logical reads 1,000-10,000: Moderate concern
- Logical reads > 10,000: High concern

**Action:**
- High reads on small result set: Missing or wrong index
- Consistent high reads: Add covering index
- Reads scale with rows: Expected (verify efficiency)

---

### 4. Number of Executions

**Location:** Operator properties, "Actual Number of Rows" / "Number of Executions"

**What it tells you:**
- How many times an operator runs
- Hidden performance multipliers
- Nested loop efficiency

**How to use:**
```
Total Rows Processed = Actual Number of Rows Ã— Number of Executions
```

**Example:**
```
Index Seek:
  Actual Number of Rows: 1
  Number of Executions: 50,000
  Total: 50,000 rows processed â† Expensive!
```

**Action:**
- Executions > 1,000: Review nested loop join
- High executions with seek: Consider hash join
- High executions on scan: Critical issue

---

### 5. Seek Predicates vs. Predicate (Filter)

**Location:** Operator properties panel

**What it tells you:**
- Which predicates use index efficiently (Seek)
- Which predicates applied after retrieval (Predicate)
- Index effectiveness

**Seek Predicates (Good):**
```
Seek Predicates: [OrderID] = 12345
â†‘ Uses index to find rows (efficient)
```

**Predicate/Filter (Bad):**
```
Predicate: [ShipDate] > '2024-01-01'
â†‘ Filters after retrieving rows (inefficient)
```

**How to use:**
- Seek Predicates: Columns in index, used efficiently
- Predicate: Columns not in index or non-sargable

**Action:**
- Predicates with high cost: Add to index
- Convert functions to SARGable format
- Create covering or filtered indexes

**Example Fix:**
```sql
-- Bad: Predicate filter
WHERE YEAR(OrderDate) = 2024

-- Good: Seek predicate
WHERE OrderDate >= '2024-01-01' AND OrderDate < '2025-01-01'
```

---

### 6. Warnings (Yellow/Red Exclamation Marks)

**Location:** Visual indicator on operators

**What it tells you:**
- Missing indexes
- Implicit conversions
- Spills to tempdb
- Join order issues

**Common Warnings:**

**Missing Index Warning:**
```
The Query Processor estimates that implementing the following 
index could improve the query cost by 95%

CREATE NONCLUSTERED INDEX [IX_Missing_123]
ON [Orders] ([CustomerID]) INCLUDE ([OrderDate], [TotalAmount])
```

**Implicit Conversion:**
```
Type conversion in expression (CONVERT_IMPLICIT(int,[MyDB].[dbo].[Orders].[CustomerID],0)) 
may affect "seek plan" in query plan choice
```

**Action:**
- Address ALL warnings
- Warnings often indicate severe problems
- Missing index warnings: Evaluate and implement
- Implicit conversions: Fix data types

---

### 7. Memory Grant

**Location:** SELECT operator (root), "MemoryGrantInfo" property

**What it tells you:**
- Memory allocated to query
- Whether query had enough memory
- Spill potential

**Fields:**
```
SerialRequiredMemory: Minimum needed
SerialDesiredMemory: Optimal amount
RequestedMemory: Actually requested
GrantedMemory: Actually granted
MaxUsedMemory: Peak usage
IsMemoryGrantFeedbackAdjusted: Feedback occurred
```

**How to use:**
```
If MaxUsedMemory > GrantedMemory:
    â† Spill occurred (very bad)
    
If GrantedMemory >> MaxUsedMemory:
    â† Over-granted (wastes memory)
```

**Action:**
- Spills: Update statistics, add memory, reduce scope
- Over-grant: Update statistics
- Consistent issues: Use query hints

**Query for memory grants:**
```sql
SELECT 
    text,
    requested_memory_kb,
    granted_memory_kb,
    used_memory_kb,
    max_used_memory_kb
FROM sys.dm_exec_query_memory_grants
CROSS APPLY sys.dm_exec_sql_text(sql_handle);
```

---

### 8. Actual Execution Mode

**Location:** Operator properties

**What it tells you:**
- Row vs. Batch mode execution
- Parallel vs. Serial execution
- Execution efficiency

**Values:**

**Row Mode:**
- Traditional row-by-row processing
- Standard for OLTP queries
- Higher CPU per row

**Batch Mode:**
- Processes rows in batches of ~900
- Much faster for analytics
- Requires columnstore or certain operators
- Lower CPU per row

**Action:**
- Large scans in row mode: Consider columnstore
- OLAP queries in row mode: Add columnstore index
- Excessive parallelism: Consider MAXDOP hints

---

### 9. Estimated Execution Plan vs. Actual Execution Plan

**Location:** SSMS toolbar or Ctrl+L (Estimated), Ctrl+M (Actual)

**What it tells you:**

**Estimated Plan:**
- What optimizer plans to do
- Based on statistics
- No actual execution
- Shows predicted costs

**Actual Plan:**
- What actually happened
- Real row counts
- Real execution metrics
- Runtime warnings

**How to use:**
```
Always compare both:
- Estimated plan for quick analysis
- Actual plan for production issues
- Compare row estimates to actuals
```

**Action:**
- Use Estimated for query tuning (faster)
- Use Actual for production issues (accurate)
- Large differences: Statistics problem

---

### 10. Sort Operations

**Location:** Sort operator in plan

**What it tells you:**
- Whether sort was needed
- Memory used for sorting
- Potential spill to tempdb

**Fields:**
```
Actual Number of Rows: Rows sorted
Estimated Row Size: Memory per row
Memory Grant: Available for sort
Spills: Whether it used tempdb
```

**How to use:**
```
Sort Cost > 20% of query:
    â† Expensive sort operation
    
Spill = TRUE:
    â† Used tempdb (very slow)
```

**Action:**
- Expensive sorts: Add index with sort order
- Spilling sorts: Increase memory or reduce rows
- Multiple sorts: Consider query rewrite

**Example Fix:**
```sql
-- Bad: Expensive sort
SELECT * FROM Orders 
WHERE CustomerID = 12345 
ORDER BY OrderDate DESC

-- Good: Index eliminates sort
CREATE INDEX IX_Orders_CustomerDate 
ON Orders(CustomerID, OrderDate DESC)
```

---

### 11. Parallelism Indicators

**Location:** Parallelism operators (Gather Streams, Distribute Streams, Repartition Streams)

**What it tells you:**
- Query uses multiple threads
- Parallel zones in plan
- Potential CXPACKET waits

**How to use:**
```
Look for:
- Gather Streams: Combines parallel results
- Distribute Streams: Splits work to threads
- Number of threads used
```

**Good Parallelism:**
- Large table scans
- Complex aggregations
- Long-running queries
- Sufficient data volume

**Bad Parallelism (overhead > benefit):**
- Small result sets (< 1000 rows)
- Simple queries
- OLTP workloads
- Excessive thread count

**Action:**
- Inappropriate parallelism: Use OPTION (MAXDOP 1)
- CXPACKET waits: Adjust cost threshold
- Small queries parallel: Increase threshold

**Configuration:**
```sql
-- Check current settings
SELECT * FROM sys.configurations 
WHERE name IN ('cost threshold for parallelism', 'max degree of parallelism');

-- Adjust cost threshold (default 5, consider 25-50)
EXEC sp_configure 'cost threshold for parallelism', 50;
RECONFIGURE;
```

---

### 12. Object Name and Index Used

**Location:** Operator properties, "Object" field

**What it tells you:**
- Which specific index was used
- Whether correct index selected
- Index usage patterns

**Format:**
```
[Database].[Schema].[Table].[IndexName]
Example: [MyDB].[dbo].[Orders].[IX_Orders_CustomerID]
```

**How to use:**
- Verify expected index is used
- Check if covering index is being leveraged
- Identify missing indexes
- Track index effectiveness

**Action:**
- Wrong index used: Update statistics
- No index used: Create appropriate index
- Table scan on indexed column: Check predicate SARGability

---

## Practical Optimization Workflow

### Step 1: Enable Actual Execution Plan
```sql
SET STATISTICS IO ON;
SET STATISTICS TIME ON;

-- Ctrl+M in SSMS or:
SET SHOWPLAN_XML ON;
```

### Step 2: Identify Expensive Operators
```
Look for operators with > 20% cost
Note: Table Scans, Index Scans, Sorts, Hash Matches
```

### Step 3: Check Row Estimate Accuracy
```
Compare Estimated vs Actual rows
Ratio > 10x: Update statistics immediately
```

### Step 4: Analyze Warnings
```
Yellow/Red warnings: Address immediately
Common: Missing indexes, implicit conversions
```

### Step 5: Review Scan Types
```
Table Scan â†’ Create index
Clustered Index Scan â†’ Add non-clustered index
Index Seek + Key Lookup (many) â†’ Create covering index
```

### Step 6: Evaluate Join Algorithms
```
Nested Loops (high executions) â†’ Consider Hash/Merge
Hash Match (spill) â†’ Update statistics, add memory
```

### Step 7: Check Logical Reads
```
SET STATISTICS IO ON
Compare logical reads across optimization attempts
Lower is better
```

### Step 8: Implement and Verify
```
Apply optimizations
Re-run with Actual Execution Plan
Compare before/after metrics
Validate improvement
```

---

## Critical SQL Server Optimization Queries

### Check Missing Indexes
```sql
SELECT 
    OBJECT_NAME(d.object_id) AS TableName,
    d.equality_columns,
    d.inequality_columns,
    d.included_columns,
    s.avg_user_impact,
    s.user_seeks + s.user_scans AS total_usage
FROM sys.dm_db_missing_index_details d
JOIN sys.dm_db_missing_index_groups g ON d.index_handle = g.index_handle
JOIN sys.dm_db_missing_index_group_stats s ON g.index_group_handle = s.group_handle
WHERE d.database_id = DB_ID()
ORDER BY s.avg_user_impact * (s.user_seeks + s.user_scans) DESC;
```

### Check Index Usage
```sql
SELECT 
    OBJECT_NAME(s.object_id) AS TableName,
    i.name AS IndexName,
    s.user_seeks,
    s.user_scans,
    s.user_lookups,
    s.user_updates,
    s.last_user_seek,
    s.last_user_scan
FROM sys.dm_db_index_usage_stats s
JOIN sys.indexes i ON s.object_id = i.object_id AND s.index_id = i.index_id
WHERE database_id = DB_ID()
ORDER BY s.user_seeks + s.user_scans + s.user_lookups DESC;
```

### Check Statistics Age
```sql
SELECT 
    OBJECT_NAME(s.object_id) AS TableName,
    s.name AS StatName,
    sp.last_updated,
    sp.rows,
    sp.rows_sampled,
    sp.modification_counter
FROM sys.stats s
CROSS APPLY sys.dm_db_stats_properties(s.object_id, s.stats_id) sp
WHERE s.object_id = OBJECT_ID('YourTableName')
ORDER BY sp.last_updated;
```

### Find Expensive Queries
```sql
SELECT TOP 20
    qs.execution_count,
    qs.total_worker_time / 1000000.0 AS total_cpu_time_sec,
    qs.total_elapsed_time / 1000000.0 AS total_elapsed_time_sec,
    qs.total_logical_reads,
    qs.total_logical_writes,
    SUBSTRING(qt.text, (qs.statement_start_offset/2)+1,
        ((CASE qs.statement_end_offset
            WHEN -1 THEN DATALENGTH(qt.text)
            ELSE qs.statement_end_offset
         END - qs.statement_start_offset)/2)+1) AS query_text,
    qp.query_plan
FROM sys.dm_exec_query_stats qs
CROSS APPLY sys.dm_exec_sql_text(qs.sql_handle) qt
CROSS APPLY sys.dm_exec_query_plan(qs.plan_handle) qp
ORDER BY qs.total_worker_time DESC;
```

---

## Best Practices Checklist

### Index Strategy
- âœ… Create indexes on frequently filtered columns
- âœ… Create covering indexes for common queries
- âœ… Index all foreign keys
- âœ… Include columns to eliminate key lookups
- âœ… Consider filtered indexes for subset queries
- âœ… Monitor and remove unused indexes
- âœ… Rebuild fragmented indexes (> 30%)

### Statistics Maintenance
- âœ… Auto-update statistics enabled
- âœ… Manual updates after bulk loads
- âœ… Full scan for small tables
- âœ… Monitor statistics age
- âœ… Check cardinality estimates regularly

### Query Writing
- âœ… Select only needed columns (no SELECT *)
- âœ… Use SARGable predicates
- âœ… Avoid functions on indexed columns
- âœ… Use appropriate data types
- âœ… Limit result sets with TOP
- âœ… Filter early in query
- âœ… Use EXISTS instead of IN for large sets

### Monitoring
- âœ… Review execution plans regularly
- âœ… Monitor expensive queries
- âœ… Track wait statistics
- âœ… Check missing index DMVs
- âœ… Verify index usage patterns
- âœ… Monitor memory grants and spills

---

## Common Performance Anti-Patterns

### 1. Function on Indexed Column (Non-SARGable)
```sql
-- BAD
WHERE YEAR(OrderDate) = 2024

-- GOOD
WHERE OrderDate >= '2024-01-01' AND OrderDate < '2025-01-01'
```

### 2. Leading Wildcard in LIKE
```sql
-- BAD
WHERE CustomerName LIKE '%Smith'

-- GOOD (if possible)
WHERE CustomerName LIKE 'Smith%'
```

### 3. OR on Different Columns
```sql
-- BAD
WHERE Category = 'Electronics' OR Price > 1000

-- GOOD
WHERE Category = 'Electronics'
UNION ALL
SELECT * FROM Products
WHERE Price > 1000 AND Category != 'Electronics'
```

### 4. Implicit Conversions
```sql
-- BAD (if UserID is INT)
WHERE UserID = '12345'

-- GOOD
WHERE UserID = 12345
```

### 5. SELECT * with Joins
```sql
-- BAD
SELECT * FROM Orders o
JOIN Customers c ON o.CustomerID = c.CustomerID

-- GOOD
SELECT o.OrderID, o.OrderDate, c.CustomerName
FROM Orders o
JOIN Customers c ON o.CustomerID = c.CustomerID
```

---

## Conclusion

Mastering SQL Server execution plans requires understanding:

1. **Scan types** - From worst (Table Scan) to best (Covering Index Seek)
2. **Join algorithms** - Context-dependent performance characteristics
3. **Key fields** - Focus on cost, row estimates, warnings, and logical reads
4. **Systematic approach** - Follow consistent optimization workflow

The most impactful optimizations typically come from:
- Creating appropriate indexes (eliminates scans)
- Maintaining current statistics (accurate estimates)
- Writing SARGable queries (enables index usage)
- Eliminating Key Lookups (covering indexes)
- Fixing implicit conversions (data type matches)

Remember: Measure before and after optimization, focus on high-impact operations first, and always validate improvements with actual execution plans and real workload testing.
